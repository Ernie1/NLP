{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family:serif; font-size:1.5em;\">Neural Conversation Model Based on Seq2seq</span>\n",
    "<span style=\"font-family:serif; font-size:1.45em;\">Jiqi Zhang (16340286)</span>\n",
    "\n",
    "## <span style=\"font-family:serif; font-size:1.2em;\">Reference</span>\n",
    "<br />\n",
    "<div style=\"font-family:serif; font-size:1.4em;\">\n",
    "\n",
    "https://github.com/Conchylicultor/DeepQA\n",
    "</div>\n",
    "\n",
    "## <span style=\"font-family:serif; font-size:1.2em;\">Environment</span>\n",
    "<br />\n",
    "<div style=\"font-family:serif; font-size:1.4em;\">\n",
    "\n",
    "- Python: 2.7.15\n",
    "- Tensorflow: 1.12.0\n",
    "</div>\n",
    "\n",
    "## <span style=\"font-family:serif; font-size:1.2em;\">Experiments</span>\n",
    "<div style=\"font-family:serif; font-size:1.4em;\">\n",
    "<br />\n",
    "Firstly, the program is adapted to Python 2.7 by replacing several functions and converting the pickle file into version 2.\n",
    "\n",
    "Secondly, the primitive training procedure is run through without modifying author's settings. It involves a two-layer Basic LSTM recurrent network cell. Its model tag is *16340286-0* and training record is in *[record/16340286-0.txt](record/16340286-0.txt)*.\n",
    "\n",
    "Its embedding projector is:\n",
    "\n",
    "![](0.png)\n",
    "\n",
    "Subsequently, it is reconstructed to involve a two-layer LSTM recurrent network cell. Its model tag is *16340286-0-lstm* and training record is in *[record/16340286-0-lstm.txt](record/16340286-0-lstm.txt)*.\n",
    "\n",
    "Its embedding projector is:\n",
    "\n",
    "![](lstm.png)\n",
    "\n",
    "\n",
    "Afterward, it is reconstructed to involve a two-layer gated recurrent unit (GRU). Its model tag is *16340286-0-gru* and training record is in *[record/16340286-0-gru.txt](record/16340286-0-gru.txt)*.\n",
    "\n",
    "Its embedding projector is:\n",
    "\n",
    "![](gru.png)\n",
    "\n",
    "Additionally, the sampled softmax loss function with 3 samples is applied in the primitive network. Its model tag is *16340286-0-softmaxSamples-3* and training record is in *[record/16340286-0-softmaxSamples-3.txt](record/16340286-0-softmaxSamples-3.txt)*.\n",
    "\n",
    "![](s3.png)\n",
    "\n",
    "To conclude, their loss is contrasted in the following graph. There are some decrepancy among basic LSTM, LSTM and GRU. It slightly reveals that the performance of GRU is better than that of LSTM meanwhile that of LSTM is better than basic LSTM. Notwithstanding the loss of the model with sampled softmax is lowest, it couldn't be demonstrated being the best because its loss function is different whereby its loss magnitude is changed. Nonetheless it facilitates the computing of loss by degrading the calculation ammount.\n",
    "\n",
    "![](loss.jpg)\n",
    "\n",
    "**Note:** *Relative* walues are incomparable because their models are run on different devices.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
